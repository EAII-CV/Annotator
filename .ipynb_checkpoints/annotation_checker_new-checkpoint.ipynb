{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import fnmatch\n",
    "import sys\n",
    "from cv2 import equalizeHist\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import json\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from PIL import Image\n",
    "import fnmatch\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "def plot_image(image, anns,class_labels):\n",
    "    \"\"\"Plots predicted bounding boxes on the image\"\"\"\n",
    "    # Create a Rectangle patch\n",
    "    df = pd.DataFrame(columns=[\"x\", \"y\", \"text\"])\n",
    "    colors = [(235, 47, 26), (235, 158, 26), (207, 235, 26), (26, 235, 64),  (26, 221, 235), (71, 26, 235), (158, 26, 235), (235, 26, 151)]\n",
    "    for ann in anns:\n",
    "        #print(\"inside fun\",len(ann),ann)\n",
    "        assert len(ann) == 4, \"box should contain  class_indx,score,poly,indx\"\n",
    "        class_pred = ann[0]\n",
    "        if(class_pred<8):\n",
    "        #box = box[2:]\n",
    "            poly_coords=[ann[2]]\n",
    "            #print(len(poly_coords))\n",
    "            cv2.drawContours(image,poly_coords, 0,colors[int(class_pred)],3)\n",
    "            #print(name, \"anns\",class_labels[int(class_pred)], poly_coords[0])\n",
    "            bbox = cv2.boundingRect(poly_coords[0])\n",
    "            #print(x_c,y_c,x_min,y_min,w,h)\n",
    "        \n",
    "            # Add the patch to the Axes\n",
    "            #image.add_patch(poly)\n",
    "            for pt in poly_coords[0]:\n",
    "                #print(pt)\n",
    "                df=df.append([{\"x\":pt[0],\"y\":pt[1], \"text\": class_labels[int(class_pred)]+\"-BI-\"+str(ann[1])+\"{\"+str(ann[3])+\"}\" }])\n",
    "            \n",
    "            #cv2.putText(img=image, text=class_labels[int(class_pred)]+\"-BI-\"+str(ann[1])+\"{\"+str(ann[3])+\"}\", org=(max(bbox[0]-5,0),max(bbox[1]-5,0)), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=2, color=colors[int(class_pred)],thickness=2)\n",
    "\n",
    "            \n",
    "       \n",
    "    return image, df\n",
    "\n",
    "    ###\n",
    "    #plt.savefig('pltsave.png')\n",
    "def extract_annotation(json_path):\n",
    "    anns=[] \n",
    "    \n",
    "    try:\n",
    "        f1 = open(json_path) \n",
    "        #f2 = open(json_path_2)\n",
    "        annotations=json.load(f1)\n",
    "        indx_counter=-1\n",
    "        for annotation in annotations:\n",
    "            #print(annotation)\n",
    "            indx_counter+=1\n",
    "            if(annotation[\"label\"]!=8 and annotation[\"label_name\"]!=\"Normal\"):\n",
    "                try:\n",
    "                    polys = np.asarray(annotation['poly'])\n",
    "                    anns.append([int(annotation[\"label\"]),annotation[\"BIRADS_level\"],polys, indx_counter])\n",
    "                    print(indx_counter,\"label:\",annotation[\"label\"],\"Level:\",annotation[\"BIRADS_level\"],\"contour\",*polys)\n",
    "                except Exception as e:\n",
    "                    print(\"error occured processing\",json_path_1)\n",
    "                #print(df_loc[\"label\"][0])\n",
    "            if(annotation[\"label\"]==8):\n",
    "                anns.append([8,annotation[\"Density_level\"],[], indx_counter])\n",
    "            if (annotation[\"label_name\"]==\"Normal\"):\n",
    "                anns.append([9,0,[], indx_counter])\n",
    "\n",
    "        f1.close()\n",
    "        \n",
    "        if len(anns)==0:  \n",
    "            print(f\"No annotation by {first_doctor}\")\n",
    "            \n",
    "        return anns\n",
    "        \n",
    "        \n",
    "    except BaseException as err:\n",
    "            print(f\"Unexpected {err=}, {type(err)=}\",json_path)\n",
    "            return anns\n",
    "##declare annotation files\n",
    "def write_json(new_data, filename='data.json'):\n",
    "    with open(filename,'r+') as file:\n",
    "          # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 6)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m joined_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sam/Desktop/new extraction/mammo1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m imsave_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sam/Desktop/new extraction/saved_fig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m ann2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(joined_data)\n\u001b[1;32m      8\u001b[0m first_doctor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWube\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m second_doctor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetty\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "class_names=[\"Mass\",\"Calcification\", \"Architectureal Distortion\", \"Asymmetry\", \"Ductal Dialtion\", \"Skin Tichening\", \"Nipple Retraction\", \"Lymphnode\"]\n",
    "birads_level_names=[\"BI-RADS 2\", \"BI-RADS 3\",\"BI-RADS 4\", \"BI-RADS 5\"]\n",
    "data_directory_1 = \"/Volumes/MLData/Paulis_Annotation/mammo__1W\"\n",
    "data_directory_2 = \"/Volumes/0973111473/Paulis_annotation2/Mammo__1Betty\"\n",
    "joined_data=\"/Users/sam/Desktop/new extraction/mammo1.csv\"\n",
    "imsave_directory=\"/Users/sam/Desktop/new extraction/saved_fig\"\n",
    "ann2 = pd.read_csv(joined_data)\n",
    "first_doctor=\"Wube\"\n",
    "second_doctor=\"Betty\"\n",
    "\n",
    "\n",
    "df_csv = pd.DataFrame(columns=[\"indx\", \"id\", \"patient_id\",\"file_name\",\"annotations\", \"needs_recheck\"])\n",
    "df_csv_ann = pd.DataFrame(columns=[\"indx\", \"id\", \"patient_id\",\"file_name\",\"class\",\"BIRADS\", \"poly\", \"ann_by\"])\n",
    "\n",
    "start_index=int(input(\"please Enter first index\"))\n",
    "if(start_index==0):\n",
    "    resp=input(\"Are you sure to delete existing data? Y|N\")\n",
    "    if resp.upper()!=\"Y\":\n",
    "        sys.exit()\n",
    "final_annotations=[]\n",
    "%matplotlib widget\n",
    "for index, row in ann2.iterrows():\n",
    "    if(index>=start_index):    \n",
    "        indx=row['indx']\n",
    "        folder_name=indx.split(\"-\")[0]\n",
    "        file_name=indx.split(\"-\")[1]+\"-\"+indx.split(\"-\")[2]+\"-\"+indx.split(\"-\")[3][:-5]\n",
    "        #print(folder_name,file_name)\n",
    "        is_normal_1=is_normal_2=False\n",
    "        density_level_1=density_level_2=-1\n",
    "        #print(\"Got Here:!\")\n",
    "        try: \n",
    "            impath= os.path.join(data_directory_1, folder_name,file_name)\n",
    "            #im_save_path=os.path.join(destination_directory,str(im_counter)+\"_\"+filename[:-4]+\".png\")\n",
    "            #print(impath)\n",
    "            \n",
    "            json_path_1=os.path.join(data_directory_1,folder_name,file_name+\".json\")\n",
    "            json_path_2=os.path.join(data_directory_2,folder_name,file_name+\".json\")\n",
    "            \n",
    "            \n",
    "        \n",
    "            ds = pydicom.dcmread(impath, force=True)\n",
    "            img= ds.pixel_array.astype(float)\n",
    "            \n",
    "            if 'WindowWidth' in ds:\n",
    "                #print('Dataset has windowing')\n",
    "                windowed  = apply_voi_lut(ds.pixel_array, ds)\n",
    "                #plt.imshow(windowed, cmap=\"gray\", vmax=windowed.max(), vmin=windowed.min)\n",
    "                #plt.show()\n",
    "                img=windowed.astype(float)\n",
    "                #return \"windowed\"\n",
    "            # Convert to uint\n",
    "            img = (np.maximum(img,0) / img.max()) * 255.0\n",
    "            img= np.uint8(img)\n",
    "            img = cv2.merge([img,img,img])\n",
    "            #img = cv2.COLOR_GRAY2RGB()\n",
    "            #(ori_h,ori_w)=img.shape\n",
    "            print(\"annotation by \",first_doctor)\n",
    "            anns_1=extract_annotation(json_path_1)\n",
    "            print(\"annotation by \",second_doctor)\n",
    "            anns_2=extract_annotation(json_path_2)\n",
    "            \n",
    "            im_1=img.copy()\n",
    "            im_2=img.copy()\n",
    "            \n",
    "            #print(\"processing file\", index, \"of \", len(ann2.index))\n",
    "            if len(anns_1)>0:          \n",
    "                im_1,df1=plot_image(im_1, anns_1,class_names)\n",
    "            if len(anns_2)>0:\n",
    "                im_2,df2=plot_image(im_2, anns_2,class_names)\n",
    "            # Create figure and axes\n",
    "            #print(df1)\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            #fig.set_size_inches(14.5, 7, forward=True)\n",
    "            \n",
    "\n",
    "            # Display the image\n",
    "            ax[0].imshow(im_1)\n",
    "            sc1=ax[0].scatter(df1[\"x\"],df1[\"y\"],s=0.01)\n",
    "            tt = df1[\"text\"].values\n",
    "            # annotation\n",
    "            annot1 = ax[0].annotate(\"\", xy=(0,0), xytext=(5,5),textcoords=\"offset points\")\n",
    "            annot1.set_visible(False)\n",
    "\n",
    "            ax[1].imshow(im_2)\n",
    "            \n",
    "            ax[0].set_title(first_doctor+\" Annotation\")\n",
    "            ax[1].set_title(second_doctor+\" Annotation\")\n",
    "            def hover(event):\n",
    "                # check if event was in the axis\n",
    "                if event.inaxes == ax[0]:\n",
    "                    \n",
    "                    \n",
    "                    # get the points contained in the event\n",
    "                    cont, ind = sc1.contains(event)\n",
    "                    #print(cont,ind)\n",
    "                    \n",
    "                    annot1.xy = (event.xdata, event.ydata)\n",
    "                    annot1.set_text(\"annotated\")\n",
    "                    annot1.set_visible(True) \n",
    "                    if cont:\n",
    "                        \n",
    "                        # change annotation position\n",
    "                        annot1.xy = (event.xdata, event.ydata)\n",
    "                        # write the name of every point contained in the event\n",
    "                        annot1.set_text(\"{}\".format(', '.join([tt[n] for n in ind[\"ind\"]])))\n",
    "                        annot1.set_visible(True)    \n",
    "                    else:\n",
    "                        annot1.set_visible(False)\n",
    "                \n",
    "                    \n",
    "            fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "\n",
    "            plt.show()\n",
    "            #print(anns_1,anns_2)\n",
    "            selected_ann_from_1 = [int(item) for item in input(\"Anntoations to keep from \"+first_doctor+\": \").split(\",\")]\n",
    "            \n",
    "            selected_ann_from_2=[int(item) for item in input(\"Anntoations to keep from \"+second_doctor+\": \").split(\",\")]\n",
    "            #print(selected_ann_from_1,selected_ann_from_2)\n",
    "            needs_recheck=input(\"does these annotation need a checkup\")\n",
    "            curr_ann=[]\n",
    "            if len(anns_1)>0:   \n",
    "                for i in selected_ann_from_1:\n",
    "                    if(i>-1):\n",
    "                        curr_ann.append({\"class\":anns_1[i][0],\"BIRADS\":anns_1[i][1], \"poly\":anns_1[i][2].tolist(),\"ann_by\":first_doctor})\n",
    "                        df_csv_ann=df_csv_ann.append([{\"indx\":indx,\"id\":index,\"patient_id\":folder_name,\"file_name\":file_name,\"class\":anns_1[i][0],\"BIRADS\":anns_1[i][1], \"poly\":anns_1[i][2].tolist(),\"ann_by\":first_doctor}], ignore_index=True)\n",
    "            if len(anns_2)>0:   \n",
    "                for i in selected_ann_from_2:\n",
    "                    if(i>-1):\n",
    "                        curr_ann.append({\"class\":anns_2[i][0],\"BIRADS\":anns_2[i][1], \"poly\":anns_2[i][2].tolist(), \"ann_by\":second_doctor})\n",
    "                        df_csv_ann=df_csv_ann.append([{\"indx\":indx,\"id\":index,\"patient_id\":folder_name,\"file_name\":file_name,\"class\":anns_2[i][0],\"BIRADS\":anns_2[i][1], \"poly\":anns_2[i][2].tolist(), \"ann_by\":second_doctor}],ignore_index=True)\n",
    "            final_annotation={indx:{\"id\": index,\"patient_id\":folder_name,\"file_name\":file_name,\"annotations\":curr_ann, \"needs_recheck\":needs_recheck}}\n",
    "            df_csv=df_csv.append([{\"indx\":indx,\"id\":index,\"patient_id\":folder_name,\"file_name\":file_name,\"annotations\":curr_ann, \"needs_recheck\":needs_recheck}], ignore_index=True)\n",
    "            print(final_annotation)\n",
    "            final_annotations.append(final_annotation)\n",
    "            #print(final_annotations)\n",
    "            print(df_csv)\n",
    "            print(df_csv_ann)\n",
    "            c=input(\"Press Enter to continue...\")\n",
    "            if c==\"q\":\n",
    "                break;\n",
    "            plt.savefig(os.path.join(imsave_directory,indx[:-5]+\".png\"))\n",
    "            plt.close('all')\n",
    "        except Exception as e:\n",
    "            print(\"General error Occured at the end\",e)\n",
    "            break;     \n",
    "\n",
    "if(start_index==0):\n",
    "    df_csv.to_csv(\"checked_data.csv\", mode=\"w\", index=False, header=True)\n",
    "    df_csv_ann.to_csv(\"checked_data_each_ann.csv\", mode=\"w\", index=False, header=True)\n",
    "    out_file = open(\"checked_data.json\", \"w\")\n",
    "    json.dump(final_annotations, out_file, indent = 6)\n",
    "    \n",
    "    out_file.close()\n",
    "\n",
    "else:\n",
    "    df_csv.to_csv(\"checked_data.csv\", mode=\"a\", index=False, header=False)\n",
    "    df_csv_ann.to_csv(\"checked_data_each_ann.csv\", mode=\"a\", index=False, header=False)\n",
    "    write_json(final_annotations, filename=\"checked_data.json\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "873d703d68e4e0757fb4b83fd65bd8689984a2379601eed2c34b7da778c0e3ef"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
